{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "295badff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Base fictícia -> dados não existem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88319a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ccce913",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importacao de bibliotecas\n",
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession, SQLContext\n",
    "from pyspark.sql import functions as f\n",
    "from pyspark.sql import types as t\n",
    "from pyspark.sql import Row\n",
    "\n",
    "from datetime import datetime,date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6901e60d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#configurando conexao\n",
    "spark = SparkSession.builder.appName('Estudo-PySpark').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f58a43f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Para ler uma base:\n",
    "base = spark.read.table('database.base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa12982",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Para subir um arquivo:\n",
    "base = pd.read_csv('base_teste.csv', sep = \";\", header = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "222a778e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Para ler de um bucket no S3\n",
    "\n",
    "import boto3\n",
    "\n",
    "bucket_inicio = 's3://bigdata-projeto/processados'\n",
    "bucket_destino = 's3://bigdata-projeto/processados'\n",
    "\n",
    "base = spark.read.parquet(bucket_inicio+'/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87f0259f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#criando um data frame\n",
    "\n",
    "colunas = ['id','nome_cliente','idade','inclusao_base']\n",
    "\n",
    "dados = [(1,2,3,4),\n",
    "         ('Marilu','Lucas','Luna','Bete'),\n",
    "         (20, 18, 20, 33),\n",
    "         (date(2021,9,10),date(2021,3,10),date(2021,9,10),date(2021,9,25))]\n",
    "\n",
    "base = spark.createDataFrame(dados).DF(*colunas)\n",
    "base.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18ca60fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Verificando a Schema da tabela\n",
    "base.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba27011",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Para filtrar use Filter\n",
    "#No caso a seguir, filtra-se registros com a data de hoje\n",
    "#O f.col referencia a coluna\n",
    "hoje = datetime.now().date()\n",
    "base = base.filter(f.col('data') == hoje)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53ef81f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pode-se particionar a base, caso a base seja reprocessada com uma certa periodicidade\n",
    "\n",
    "#Particionando a base pegando os dados mais recentes\n",
    "win = Window.partitionBy(f.col('id_cliente')).orderBy(f.col('data_processamento').cast('date').desc())\n",
    "base = base.withColumn('col_rank', f.row_number().over(win)).filter(('col_rank' == 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb9d10d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Para criar uma nova coluna use WithColumn(nome da coluna, condição)\n",
    "#Caso tenha que usar if, use f.when, o else é otherwise\n",
    "\n",
    "base_feminina = base.withColumn('flag_genero',f.when(f.col('genero') == \"M\",'sim').otherwise('não'))\\\n",
    "                    .filter(f.col('flag_genero') == 'sim')\n",
    "\n",
    "#Pode-se renomear o nome da coluna usando WithColumnRenamed\n",
    "base_feminina2 = base.withColumnRenamed('genero','genero_cliente')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85eb1e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Para selecionar colunas use Select\n",
    "base_feminina.select('flag_genero','genero').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d4d107",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cruzamento entre tabelas\n",
    "#duas tabelas: vendas e produtos\n",
    "\n",
    "#Schema tb_vendas:\n",
    "#        | id_venda | id_produto | quantidade | valor |\n",
    "#          ----------------------------------------\n",
    "#            int    |    int     |     int    | double\n",
    "#          ----------------------------------------\n",
    "\n",
    "#Schema tb_produtos:\n",
    "#        | id_produto | valor  | nome_produto |\n",
    "#          ----------------------------------\n",
    "#             int     | double |    string    |\n",
    "#          ----------------------------------\n",
    "\n",
    "#o cruzamento será da tb_vendas com a tb_produtos para pegar nome do produto para cada venda, então será um left join\n",
    "tb_vendas.join(tb_produtos, tb_vendas['id_produto'] == tb_produtos['id_produto'], 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed85979a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Para armazenar os dados processados em um csv no S3\n",
    "\n",
    "base.write.option(\"header\", True).csv(bucket_destino+'/dados_processados.csv', sep=\";\")\n",
    "\n",
    "#Para um diretorio\n",
    "base.write.option(\"header\", True).csv('diretorio_local')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
